{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_parquet('data/training_data.parquet')\n",
    "test = pd.read_parquet('data/testing_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test data into features X and targets Y.\n",
    "target_column_name = 'readmit_status'\n",
    "Y_train = train[target_column_name]\n",
    "X_train = train.drop([target_column_name], axis = 1)  \n",
    "Y_test = test[target_column_name]\n",
    "X_test = test.drop([target_column_name], axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Transform string data to numeric one-hot vectors\n",
    "categorical_selector = selector(dtype_exclude=np.number)\n",
    "categorical_columns = categorical_selector(X_train)\n",
    "categorial_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Standardize numeric data by removing the mean and scaling to unit variance\n",
    "numerical_selector = selector(dtype_include=np.number)\n",
    "numerical_columns = numerical_selector(X_train)\n",
    "numerical_encoder = StandardScaler()\n",
    "\n",
    "# Create a preprocessor that will preprocess both numeric and categorical data\n",
    "preprocessor = ColumnTransformer([\n",
    "('categorical-encoder', categorial_encoder, categorical_columns),\n",
    "('standard_scaler', numerical_encoder, numerical_columns)])\n",
    "\n",
    "clf = make_pipeline(preprocessor, LogisticRegression())\n",
    "\n",
    "print('Training model...') \n",
    "model = clf.fit(X_train, Y_train)\n",
    "print('Accuracy score: ', clf.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = MLClient.from_config(credential=credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "train_data_name = 'hospital_train_parquet'\n",
    "test_data_name = 'hospital_test_parquet'\n",
    "\n",
    "training_data = Data(\n",
    "    name=train_data_name,\n",
    "    path='data/training_data.parquet',\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    description='RAI hospital train data'\n",
    ")\n",
    "tr_data = ml_client.data.create_or_update(training_data)\n",
    "\n",
    "test_data = Data(\n",
    "    name=test_data_name,\n",
    "    path='data/testing_data.parquet',\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    description='RAI hospital test data'\n",
    ")\n",
    "ts_data = ml_client.data.create_or_update(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "import time\n",
    "\n",
    "compute_name = 'trainingcompute'\n",
    "\n",
    "my_compute = AmlCompute(\n",
    "    name=compute_name,\n",
    "    size='Standard_DS12_v2',\n",
    "    min_instances=0,\n",
    "    max_instances=4,\n",
    "    idle_time_before_scale_down=3600\n",
    ")\n",
    "ml_client.compute.begin_create_or_update(my_compute).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command, Input, Output\n",
    "\n",
    "target_column_name = 'readmit_status'\n",
    "\n",
    "# Create the job.\n",
    "job = command(\n",
    "    description='Trains hospital readmission model',\n",
    "    experiment_name='hospital_readmission',\n",
    "    compute=compute_name,\n",
    "    inputs=dict(training_data=Input(type='uri_file', path=f'{train_data_name}@latest'), \n",
    "                target_column_name=target_column_name),\n",
    "    outputs=dict(model_output=Output(type=AssetTypes.MLFLOW_MODEL)),\n",
    "    code='src/',\n",
    "    environment='azureml://registries/azureml/environments/AzureML-responsibleai-0.20-ubuntu20.04-py38-cpu/versions/37',\n",
    "    command='python train.py ' + \n",
    "            '--training_data ${{inputs.training_data}} ' +\n",
    "            '--target_column_name ${{inputs.target_column_name}} ' +\n",
    "            '--model_output ${{outputs.model_output}}'\n",
    ")\n",
    "job = ml_client.jobs.create_or_update(job)\n",
    "ml_client.jobs.stream(job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "\n",
    "model_name = 'hospital_readmission_model'\n",
    "\n",
    "# Register the model.\n",
    "model_path = f'azureml://jobs/{job.name}/outputs/model_output'\n",
    "model = Model(name=model_name,\n",
    "                path=model_path,\n",
    "                type=AssetTypes.MLFLOW_MODEL)\n",
    "registered_model = ml_client.models.create_or_update(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
